{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34044911-108c-4d34-97e8-0b0d90aebee3",
   "metadata": {},
   "source": [
    "# Calibrate probes based on s1K trajectories\n",
    "\n",
    "Pretrained probes and calibrated decision thresholds may be downloaded [here](https://figshare.com/articles/dataset/s1K_calibrated_probes/29242328). These files should be placed under `PROBE_DIR`.\n",
    "\n",
    "Code is provided for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f0e9bc-87d7-4e9f-8ac2-5abc009e5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from collections import Counter, deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import binom\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a847cf-dd95-4902-824f-207e021fa59a",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6453a4ac-cf14-4046-854e-b91286f68b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBE_DATA_DIR = \"../probes/data\"  # LLM embeddings\n",
    "PROBE_DIR = \"../probes\"  # you can customize\n",
    "\n",
    "# this should be updated with where your outputs are saved\n",
    "model_to_folder = {\n",
    "    \"qwen2.5\": \"../outputs\",\n",
    "    \"qwq\": \"../outputs-qwq\",\n",
    "    \"llama3.3\": \"../outputs-llama\"\n",
    "}\n",
    "\n",
    "# you can modify code to loop through instead if you wish\n",
    "MODEL = \"qwen2.5\"    # qwen2.5|qwq|llama3.3\n",
    "MODE = \"supervised\"  # supervised|consistent|novel|leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1aee6f-75c2-4c48-b6f9-e2ceb3da71dd",
   "metadata": {},
   "source": [
    "Our s1K splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e0da56-4ff0-4ccb-b6d4-8304f3868e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    \"train\": range(500),\n",
    "    \"val\": range(500, 550),\n",
    "    \"test\": range(550, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07682f9-6c25-4e3f-8f8a-7d623b7f7d10",
   "metadata": {},
   "source": [
    "## Functions for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0497b6c-f233-4f50-b227-f6fa77158955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probe_inputs(model):\n",
    "    with open(os.path.join(PROBE_DATA_DIR, f\"{model}_embed_steps.pkl\"), \"rb\") as f:\n",
    "        reps = pickle.load(f)\n",
    "    return reps\n",
    "\n",
    "\n",
    "def load_probe_labels(model, mode=\"supervised\"):\n",
    "    \"\"\"\n",
    "    mode  (str) supervised|consistent|novel|leaf\n",
    "    \"\"\"\n",
    "    # novel and leaf labels are not dependent on model\n",
    "    if mode in [\"supervised\", \"consistent\"]:\n",
    "        fp_labels = f\"labels-{mode}-{model}.json\"\n",
    "    else:\n",
    "        fp_labels = f\"labels-{mode}.json\"\n",
    "    # load JSON\n",
    "    with open(os.path.join(PROBE_DATA_DIR, fp_labels)) as f:\n",
    "        labels = json.load(f)\n",
    "        index = labels[\"index\"]\n",
    "        label = labels[\"label\"]\n",
    "    assert len(index) == len(label)\n",
    "    # transform label to cumulative for supervised|consistent\n",
    "    # for calibration validity\n",
    "    if mode in [\"supervised\", \"consistent\"]:\n",
    "        to_cumulative(index, label)\n",
    "    return index, label\n",
    "\n",
    "def to_cumulative(index, label):\n",
    "    \"\"\"\n",
    "    applied for supervised and consistent probe.\n",
    "    modifies `label` and `index` in place.\n",
    "    \"\"\"\n",
    "    for i, lbl in enumerate(label):\n",
    "        if 1 not in lbl:\n",
    "            label[i] = []  # skip\n",
    "            index[i] = []\n",
    "            continue\n",
    "        first = lbl.index(1)\n",
    "        for j in range(first, len(lbl)):\n",
    "            lbl[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb3075e-3607-413c-b8af-bc8c1db1e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_p(loss, eps):\n",
    "    \"\"\"\n",
    "    Binomial tails p-value\n",
    "    \"\"\"\n",
    "    p_value = binom.cdf(k=np.sum(loss), n=len(loss), p=eps)\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def get_loss(pred, true, lam):\n",
    "    \"\"\"\n",
    "    \"Loss\" in the learn-then-test sense\n",
    "    \"\"\"\n",
    "    pred_bin = [1 if p >= lam else 0 for p in pred]\n",
    "    if 1 not in pred_bin:\n",
    "        return 1 - true[-1]\n",
    "    idx = min(pred_bin.index(1), len(true) - 1)\n",
    "    return 1 - true[idx]\n",
    "\n",
    "\n",
    "def run_test(preds, trues, eps, bins=10000, loss_f=get_loss):\n",
    "    \"\"\"\n",
    "    Fixed sequence testing procedure\n",
    "    \"\"\"\n",
    "    lambda_range = [1 - i / bins for i in range(bins)]\n",
    "    for lam in lambda_range:\n",
    "        loss = [loss_f(p, t, lam) for p, t in zip(preds, trues)]\n",
    "        pval = binom_p(loss, eps)\n",
    "        if pval > eps:\n",
    "            break\n",
    "    return lam\n",
    "\n",
    "\n",
    "def smooth(pred, window=1):\n",
    "    \"\"\"\n",
    "    Rolling window for smoothing\n",
    "    \"\"\"\n",
    "    queue = deque()\n",
    "    pred_smooth = []\n",
    "    for p in pred:\n",
    "        queue.append(p)\n",
    "        if len(queue) > window:\n",
    "            queue.popleft()\n",
    "        pred_smooth.append(np.mean(queue))\n",
    "    return pred_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0ecc1-a235-48e0-ae16-9ca26ecb4e06",
   "metadata": {},
   "source": [
    "## Supervised and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6782caa-f3bd-48a0-aade-cb469a986fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambdas(model, mode,\n",
    "                eps=[0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5],\n",
    "                batch_size=10):\n",
    "    \"\"\"\n",
    "    Compute thresholds (lambdas)\n",
    "\n",
    "    model       (str) supervised|consistent only. see below for novel and leaf\n",
    "    eps         (list[float]) risk tolerance\n",
    "    batch_size  (int) should match generate_truncated_prompts\n",
    "    \"\"\"\n",
    "    # load embeddings\n",
    "    step_embeddings = load_probe_inputs(model)\n",
    "    # load model and labels\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-{mode}-{model}.pkl\"), \"rb\") as f:\n",
    "        lr, scaler, pca = pickle.load(f)\n",
    "    index, label = load_probe_labels(model, mode)\n",
    "    # make predictions\n",
    "    ebs_to_keep = [step_embeddings[i] for i in splits[\"test\"] if len(label[i]) > 0]\n",
    "    preds = [lr.predict_proba(pca.transform(scaler.transform(ebds)))[:,1] for ebds in ebs_to_keep]\n",
    "    preds = [smooth(p, window=10) for p in preds]\n",
    "    # expand labels to step-wise\n",
    "    trues = []\n",
    "    labels_to_keep = [label[i] for i in splits[\"test\"] if len(label[i]) > 0]\n",
    "    for i, lbl in enumerate(labels_to_keep):\n",
    "        lbl = [item for item in lbl for _ in range(batch_size)]\n",
    "        lbl = lbl[:len(preds[i])]  # trim off excess\n",
    "        trues.append(lbl)\n",
    "    \n",
    "    lambdas = {}\n",
    "    for ep in eps:\n",
    "        lam = run_test(preds, trues, ep, loss_f=get_loss)\n",
    "        lambdas[ep] = lam\n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10337f71-65e7-4629-bf07-dff05addebcf",
   "metadata": {},
   "source": [
    "This takes about 1-2 minutes per model, for the default eps range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7287bb6-53de-433d-9f59-a6c4ae6cc87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in [\"supervised\", \"consistent\"]:\n",
    "    for model in model_to_folder:\n",
    "        fp_out = os.path.join(PROBE_DIR, f\"lambdas-{model}-{MODE}.json\")\n",
    "        if os.path.exists(fp_out):\n",
    "            continue\n",
    "        lambdas = get_lambdas(model, MODE)\n",
    "        with open(fp_out, \"w\") as f:\n",
    "            json.dump(lambdas, f)\n",
    "        print(fp_out, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf789a-03c0-432e-a7f4-aefebe8977a4",
   "metadata": {},
   "source": [
    "## Novel leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef27941-a2aa-412c-aa0f-5a6821576164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambdas_boring(model,\n",
    "                       eps=[0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5],\n",
    "                       batch_size=10):\n",
    "    \"\"\"\n",
    "    Compute thresholds (lambdas) for novel leaf probe\n",
    "\n",
    "    model       (str) supervised|consistent only. see below for novel and leaf\n",
    "    eps         (list[float]) risk tolerance\n",
    "    batch_size  (int) should match generate_truncated_prompts\n",
    "    \"\"\"\n",
    "    # load embeddings\n",
    "    step_embeddings = load_probe_inputs(model)\n",
    "\n",
    "    # load model\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-leaf-{model}.pkl\"), \"rb\") as f:\n",
    "        lr_leaf, scaler_leaf, pca_leaf = pickle.load(f)\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-novel-{model}.pkl\"), \"rb\") as f:\n",
    "        lr_novel, scaler_novel, pca_novel = pickle.load(f)\n",
    "    # load consistency labels\n",
    "    index, label = load_probe_labels(model, \"consistent\")\n",
    "    # make predictions\n",
    "    ebs_to_keep = [step_embeddings[i] for i in splits[\"test\"] if len(label[i]) > 1]\n",
    "    p_boring_leaf = []\n",
    "    for cur_reps in ebs_to_keep:\n",
    "        # p(leaf)\n",
    "        leaf_preds = lr_leaf.predict_proba(pca_leaf.transform(scaler_leaf.transform(cur_reps)))[:,1]\n",
    "        # p(novel)\n",
    "        cur_reps_stacked = np.concatenate([cur_reps[1:], cur_reps[:-1]], axis=1)  # look back\n",
    "        novel_preds = lr_novel.predict_proba(pca_novel.transform(scaler_novel.transform(cur_reps_stacked)))[:,1]\n",
    "        # p_boring_leaf = p(leaf) * (1 - p(novel))\n",
    "        p_boring = leaf_preds[1:] * (1 - novel_preds)\n",
    "        p_boring_leaf.append(smooth(p_boring, window=10))\n",
    "\n",
    "    # expand labels to step-wise\n",
    "    trues = []\n",
    "    labels_to_keep = [label[i] for i in splits[\"test\"] if len(label[i]) > 1]\n",
    "    for i, lbl in enumerate(labels_to_keep):\n",
    "        lbl = [item for item in lbl for _ in range(10)]\n",
    "        lbl = lbl[1:len(p_boring_leaf[i])+1]  # trim off first and excess\n",
    "        trues.append(lbl)\n",
    "    \n",
    "    lambdas = {}\n",
    "    for ep in eps:\n",
    "        lam = run_test(p_boring_leaf, trues, ep, loss_f=get_loss)\n",
    "        lambdas[ep] = lam\n",
    "\n",
    "    return lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4bc81b-23c5-487d-ae2f-93546fbdb04d",
   "metadata": {},
   "source": [
    "This takes ~4 minutes per model because there are two probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7df735-3618-4096-91b5-6d231d0ca54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"boring\"\n",
    "for model in model_to_folder:\n",
    "    fp_out = os.path.join(PROBE_DIR, f\"lambdas-{model}-{MODE}.json\")\n",
    "    if os.path.exists(fp_out):\n",
    "        continue\n",
    "    lambdas = get_lambdas_boring(model)\n",
    "    with open(fp_out, \"w\") as f:\n",
    "        json.dump(lambdas, f)\n",
    "    print(fp_out, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc887da-80d7-43fe-808e-df56c8539cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
