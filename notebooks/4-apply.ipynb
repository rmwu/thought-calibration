{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34044911-108c-4d34-97e8-0b0d90aebee3",
   "metadata": {},
   "source": [
    "# Apply probes for early stopping\n",
    "\n",
    "Pretrained probes and calibrated decision thresholds may be downloaded [here](https://figshare.com/articles/dataset/s1K_calibrated_probes/29242328). These files should be placed under `PROBE_DIR`.\n",
    "\n",
    "Code is provided for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f0e9bc-87d7-4e9f-8ac2-5abc009e5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# hi sklearn\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a847cf-dd95-4902-824f-207e021fa59a",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6453a4ac-cf14-4046-854e-b91286f68b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBE_DATA_DIR = \"../probes/data\"  # LLM embeddings\n",
    "PROBE_DIR = \"../probes\"  # you can customize\n",
    "\n",
    "# this should be updated with where your outputs are saved\n",
    "model_to_folder = {\n",
    "    \"qwen2.5\": \"../outputs\",\n",
    "    \"qwq\": \"../outputs-qwq\",\n",
    "    \"llama3.3\": \"../outputs-llama\"\n",
    "}\n",
    "\n",
    "# you can modify code to loop through instead if you wish\n",
    "MODEL = \"qwen2.5\"    # qwen2.5|qwq|llama3.3\n",
    "MODE = \"supervised\"  # supervised|consistent|novel|leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1aee6f-75c2-4c48-b6f9-e2ceb3da71dd",
   "metadata": {},
   "source": [
    "Our s1K splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e0da56-4ff0-4ccb-b6d4-8304f3868e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    \"train\": range(500),\n",
    "    \"val\": range(500, 550),\n",
    "    \"test\": range(550, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07682f9-6c25-4e3f-8f8a-7d623b7f7d10",
   "metadata": {},
   "source": [
    "## Determine stopping time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0497b6c-f233-4f50-b227-f6fa77158955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probe_inputs(model):\n",
    "    with open(os.path.join(PROBE_DATA_DIR, f\"{model}_embed_steps.pkl\"), \"rb\") as f:\n",
    "        reps = pickle.load(f)\n",
    "    return reps\n",
    "\n",
    "\n",
    "def smooth(pred, window=1):\n",
    "    \"\"\"\n",
    "    Rolling window for smoothing\n",
    "    \"\"\"\n",
    "    queue = deque()\n",
    "    pred_smooth = []\n",
    "    for p in pred:\n",
    "        queue.append(p)\n",
    "        if len(queue) > window:\n",
    "            queue.popleft()\n",
    "        pred_smooth.append(np.mean(queue))\n",
    "    return pred_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0ecc1-a235-48e0-ae16-9ca26ecb4e06",
   "metadata": {},
   "source": [
    "## Supervised and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7287bb6-53de-433d-9f59-a6c4ae6cc87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stops(model, mode, eps):\n",
    "    \"\"\"\n",
    "    eps      (float) tolerance. selected in `3-calibrate.ipynb`\n",
    "\n",
    "    return stop (list[int]) in units of steps\n",
    "    \"\"\"\n",
    "    # load everything\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-{mode}-{model}.pkl\"), \"rb\") as f:\n",
    "        lr, scaler, pca = pickle.load(f)\n",
    "    with open(os.path.join(PROBE_DIR, f\"lambdas-{model}-{mode}.json\")) as f:\n",
    "        ltt_lambdas = json.load(f)\n",
    "    step_embeddings = load_probe_inputs(model)\n",
    "\n",
    "    # apply probe at threshold\n",
    "    if eps not in ltt_lambdas:\n",
    "        raise Exception(f\"Invalid eps. Choose from: {sorted(ltt_lambdas)}\")\n",
    "    threshold = ltt_lambdas[eps]\n",
    "    stop = []\n",
    "    for i in splits[\"val\"]:  # val is test, test is cal\n",
    "        ebds = step_embeddings[i]\n",
    "        probs = lr.predict_proba(pca.transform(scaler.transform(ebds)))[:, 1]\n",
    "        probs = smooth(probs, window=10)\n",
    "        early_t = len(probs) - 1\n",
    "        for t, p in enumerate(probs):\n",
    "            if p >= threshold:\n",
    "                early_t = t\n",
    "                break\n",
    "        stop.append(early_t)\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6f328-1ff8-4ea2-a9aa-569c3ce76f16",
   "metadata": {},
   "source": [
    "Example usage. Options for eps:\n",
    "    ['0.01', '0.025', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f054f396-1485-44e0-a23a-286b35598877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 35, 46, 56, 48]\n",
      "50 [16, 34, 46, 56, 27]\n",
      "50 [16, 32, 46, 56, 19]\n",
      "50 [16, 31, 46, 56, 18]\n",
      "50 [16, 30, 45, 56, 18]\n",
      "50 [16, 28, 44, 54, 11]\n",
      "50 [10, 26, 30, 49, 3]\n"
     ]
    }
   ],
   "source": [
    "for eps in ['0.01', '0.025', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.5']:\n",
    "    stop = get_stops(MODEL, MODE, eps)\n",
    "    print(len(stop), stop[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf789a-03c0-432e-a7f4-aefebe8977a4",
   "metadata": {},
   "source": [
    "## Novel leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef27941-a2aa-412c-aa0f-5a6821576164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stops_boring(model, eps):\n",
    "    \"\"\"\n",
    "    eps      (float) tolerance\n",
    "\n",
    "    return stop (list[int]) in units of steps\n",
    "    \"\"\"\n",
    "    # load everything\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-leaf-{model}.pkl\"), \"rb\") as f:\n",
    "        lr_leaf, scaler_leaf, pca_leaf = pickle.load(f)\n",
    "    with open(os.path.join(PROBE_DIR, f\"probe-novel-{model}.pkl\"), \"rb\") as f:\n",
    "        lr_novel, scaler_novel, pca_novel = pickle.load(f)\n",
    "    with open(os.path.join(PROBE_DIR, f\"lambdas-{model}-boring.json\")) as f:\n",
    "        ltt_lambdas = json.load(f)\n",
    "    step_embeddings = load_probe_inputs(model)\n",
    "\n",
    "    # apply probe at threshold\n",
    "    if eps not in ltt_lambdas:\n",
    "        raise Exception(f\"Invalid eps. Choose from: {sorted(ltt_lambdas)}\")\n",
    "    threshold = ltt_lambdas[eps]\n",
    "\n",
    "    stop = []\n",
    "    for i in splits[\"val\"]:\n",
    "        cur_reps = step_embeddings[i]\n",
    "        if len(cur_reps) < 2:\n",
    "            stop.append(len(cur_reps))\n",
    "            continue\n",
    "\n",
    "        # p(leaf)\n",
    "        leaf_preds = lr_leaf.predict_proba(pca_leaf.transform(scaler_leaf.transform(cur_reps)))[:,1]\n",
    "        # # p(novel)\n",
    "        cur_reps_stacked = np.concatenate([cur_reps[1:], cur_reps[:-1]], axis=1)  # look back\n",
    "        novel_preds = lr_novel.predict_proba(pca_novel.transform(scaler_novel.transform(cur_reps_stacked)))[:,1]\n",
    "\n",
    "        p_boring = leaf_preds[1:] * (1 - novel_preds)\n",
    "        probs = smooth(p_boring, window=10)\n",
    "\n",
    "        early_t = len(probs) # we started from 1 so last is ok\n",
    "        for t, p in enumerate(probs):\n",
    "            if p >= threshold:\n",
    "                early_t = t\n",
    "                break\n",
    "\n",
    "        stop.append(early_t)\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc887da-80d7-43fe-808e-df56c8539cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 46, 46, 56, 48]\n",
      "50 [16, 46, 10, 56, 48]\n",
      "50 [16, 46, 0, 56, 48]\n",
      "50 [16, 18, 0, 56, 48]\n",
      "50 [16, 17, 0, 56, 48]\n",
      "50 [6, 16, 0, 56, 48]\n",
      "50 [6, 16, 0, 56, 48]\n",
      "50 [2, 5, 0, 56, 48]\n",
      "50 [2, 5, 0, 55, 48]\n",
      "50 [1, 1, 0, 5, 14]\n"
     ]
    }
   ],
   "source": [
    "for eps in ['0.01', '0.025', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.5']:\n",
    "    stop = get_stops_boring(MODEL, eps)\n",
    "    print(len(stop), stop[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
